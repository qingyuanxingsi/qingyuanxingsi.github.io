<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>苹果的味道</title>
    <meta name="description" content="">
    <meta name="author" content="qingyuanxingsi">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
    <script src="../theme/html5.js"></script>
    <![endif]-->

    <!-- Le styles -->
    <link href="//netdna.bootstrapcdn.com/twitter-bootstrap/2.1.1/css/bootstrap.no-icons.min.css" rel="stylesheet">
    <link href="../theme/local.css" rel="stylesheet">
    <link href="../theme/pygments.css" rel="stylesheet">
    <link href="../theme/font-awesome.css" rel="stylesheet">
    <link href='http://fonts.googleapis.com/css?family=Gudea:400,400italic|Alegreya+SC' rel='stylesheet' type='text/css'>
</head>

<body>
<header class="blog-header">
  <div class="container">
    <div class="row-fluid">
      <div class="span9">
	<a href=".." class="brand">苹果的味道</a>
      </div>

      <div class="span3" id="blog-nav">
	<ul class="nav nav-pills pull-right">
            <li><a href="../pages/about.html">About</a></li>
	    <li >
	      <a href="../category/distributed-system.html ">Distributed System</a>
	    <li >
	      <a href="../category/life.html ">Life</a>
	    <li >
	      <a href="../category/machine-learning.html ">Machine Learning</a>
	    <li >
	      <a href="../category/notes.html ">Notes</a>
	    <li >
	      <a href="../category/pearls.html ">Pearls</a>
	    <li >
	      <a href="../category/viewpoint.html ">Viewpoint</a>
	</ul>
      </div>
    </div> <!-- End of fluid row-->
  </div>   <!-- End of Container-->
</header>
    
<div class="container">
    <div class="content">
    <div class="row-fluid">

        <div class="span10">
        

        

    <div class='row-fluid''>
        <div class="article-title span9">
            <a href="../zi-ran-yu-yan-chu-li-xu-zhang-wo-ai-zi-ran-yu-yan-chu-li.html"><h1>自然语言处理(序章):我爱自然语言处理</h1></a>
        </div>
    </div>
    <div class="row-fluid">
      <div class="span2">
<p>一 05 五月 2014 </p>

<p style="text-align: left;">
Filed under <a href="../category/pearls.html">Pearls</a>
</p>
<p style="text-align: left;">
 
    Tags <a href="../tag/nlp.html">NLP</a> </p>
<p>
</p>
      </div>
      <div class="article-content span8">
	<p>昨天浏览了一下<a href="http://www.52nlp.cn">我爱自然语言处理</a>站点上的全部文章,然后基本过滤下来自己感兴趣的90篇左右的文章,这一阵子就先把这90篇文章认认真真看完吧,总结看的过程中自己感兴趣而且重要的点,遂成此文。<strong>本文中所有资料属我爱自然语言处理及博客原文引用作者所有,特此声明</strong>。</p>
<h1>齐夫定律(Zipf’s Law)</h1>
<hr>
<blockquote>
<p><strong>Zipf's Law</strong>:</p>
<p>在任何一个自然语言里第$n$个最常用的单词的频率与$n$近似成反比(The frequency of use of the nth-most-frequently-used word in any natural language is approximately inversely proportional to n).更正式地,我们可以说:存在一个常量$k$,使得:</p>
<p>\begin{equation}
f \times r =k
\end{equation}</p>
<p>其中$f$表示单词出现的频度,$r$表示单词出现次数的排名(RANK).</p>
</blockquote>
<p><img alt="Zipf" src="http://i1302.photobucket.com/albums/ag136/qingyuanxingsi/blog/zipf_zpsae557119.png"></p>
<p>北京大学姜望琪老师的《Zipf与省力原则》讲得很好，部分摘录如下:</p>
<ol>
<li>省力原则(the Principle of Least Effort)，又称经济原则(the Economy Principle)，可以概括为：以最小的代价换取最大的收益。这是指导人类行为的一条根本性原则。在现代学术界，第一个明确提出这条原则的是美国学者 George Kingsley Zipf。　　</li>
<li>George Kingsley Zipf1902年1月出生于一个德裔家庭（其祖父十九世纪中叶移居美国)。1924年，他以优异成绩毕业于哈佛学院。1925年在德国波恩、柏林学习。1929年完成Relative Frequency as a Determinant of Phonetic Change，获得哈佛比较语文学博士学位。然后，他开始在哈佛教授德语。1931年与Joyce Waters Brown结婚。1932年出版Selected Studies of the Principle of Relative Frequency in Language。1935年出版The Psycho- Biology of Language：An Introduction to Dynamic Philology。1939年被聘为讲师。1949年出版Human Behavior and the Principle of Least Effort：An Introduction to Human Ecology。1950年9月因患癌症病逝。　　</li>
<li>
<p>Zipf在1949年的书里提出了一条指导人类行为的基本原则——省力原则。Zipf在序言里指出，如果我们把人类行为纯粹看作一种自然现象，如果我们像研究蜜蜂的社会行为、鸟类的筑巢习惯一样研究人类行为，那么，我们就有可能揭示其背后的基本原则。这是他提出“省力原则”的大背景。当Zipf在众多互不相干的现象里都发现类似Zipf定律的规律性以后，他就开始思考造成这种规律性的原因。这是导致他提出“省力原则”的直接因素。在开始正式论证以前，Zipf首先澄清了“省力原则”的字面意义。</p>
<ul>
<li>第一，这是一种平均量。一个人一生要经历很多事情，他在一件事情上的省力可能导致在另一件事情上的费力。反过来，在一件事情上的费力，又可能导致在另一件事情上的省力。</li>
<li>第二，这是一种概率。一个人很难在事先百分之百地肯定某种方法一定能让他省力，他只能有一个大概的估计。因为用词研究是理解整个言语过程的关键，而后者又是理解整个人类生态学的关键，他的具体论证从用词经济开始。Zipf认为，用词经济可以从两个角度来讨论：说话人的角度和听话人的角度。从说话人的角度看，用一个词表达所有的意义是最经济的。这样，说话人不需要花费气力去掌握更多的词汇，也不需要考虑如何从一堆词汇中选择一个合适的词。这种“单一词词汇量”就像木工的一种多用工具，集锯刨钻锤于一身，可以满足多种用途。但是，从听话人角度看，这种“单一词词汇量”是最费力的。他要决定这个词在某个特定场合到底是什么意思，而这几乎是不可能的。相反，对听话人来说，最省力的是每个词都只有一个意义，词汇的形式和意义之间完全一一对应。这两种经济原则是互相冲突、互相矛盾的。Zipf把它们叫做一条言语流中的两股对立的力量：“单一化力量”（the Force of Unification）和“多样化力量”（the Force of Diversification）。他认为，这两股力量只有达成妥协，达成一种平衡，才能实现真正的省力。事实正像预计的那样。请看Zipf的论证：假如只有单一化力量，那么任何语篇的单词数量（number）都会是1，而它的出现次数（frequency）会是100%。另一方面，假如只有多样化力量，那么每个单词的出现次数都会接近1，而单词总数量则由语篇的长度决定。这就是说， <em>number</em>和<em>frequency</em>是衡量词汇平衡程度的两个参数。</li>
</ul>
</li>
</ol>
<h1>中文分词</h1>
<hr>
<p>对于英文而言,由于词自然一般有非常自然的分隔符(空格或标点符号等),因此对于英文而言基本不涉及分词这个任务,而对于中文而言,因为中文没有非常明显的自然分隔符,而且很多自然语言处理任务很大程度上依赖于分词质量,因此中文分词是中文自然语言处理中非常基础且重要的一个任务,以下对中文分词中涉及的基本算法做一个简要的介绍:</p>
<h2>最长正向匹配算法</h2>
<p>最长正向匹配算法的基本流程如下图所示:</p>
<p><img alt="MAX_SEGMENTATION" src="http://i1302.photobucket.com/albums/ag136/qingyuanxingsi/blog/max_segmentation_zpsadc70b2d.png"></p>
<p>逆向匹配法思想与正向一样，只是从右向左切分，这里举一个例子：</p>
<p>输入例句:S1=”计算语言学课程有意思”;</p>
<p>定义:最大词长MaxLen = 5；S2="";分隔符="/"；</p>
<p>假设存在词表:计算语言学,课程,意思,...；最大逆向匹配分词算法过程如下：</p>
<ol>
<li>S2=””；S1不为空，从S1右边取出候选子串W=”课程有意思”；</li>
<li>查词表，W不在词表中，将W最左边一个字去掉，得到W=”程有意思”；</li>
<li>查词表，W不在词表中，将W最左边一个字去掉，得到W=”有意思”；</li>
<li>查词表，W不在词表中，将W最左边一个字去掉，得到W=”意思”</li>
<li>查词表，“意思”在词表中，将W加入到S2中，S2=” 意思/”，并将W从S1中去掉，此时S1=”计算语言学课程有”；</li>
<li>S1不为空，于是从S1左边取出候选子串W=”言学课程有”；</li>
<li>查词表，W不在词表中，将W最左边一个字去掉，得到W=”学课程有”；</li>
<li>查词表，W不在词表中，将W最左边一个字去掉，得到W=”课程有”；</li>
<li>查词表，W不在词表中，将W最左边一个字去掉，得到W=”程有”；</li>
<li>查词表，W不在词表中，将W最左边一个字去掉，得到W=”有”，这W是单字，将W加入到S2中，S2=“/有/意思”，并将W从S1中去掉，此时S1=”计算语言学课程”；</li>
<li>S1不为空，于是从S1左边取出候选子串W=”语言学课程”；</li>
<li>查词表，W不在词表中，将W最左边一个字去掉，得到W=”言学课程”；</li>
<li>查词表，W不在词表中，将W最左边一个字去掉，得到W=”学课程”；</li>
<li>查词表，W不在词表中，将W最左边一个字去掉，得到W=”课程”；</li>
<li>查词表，“意思”在词表中，将W加入到S2中，S2=“ 课程/ 有/ 意思/”，并将W从S1中去掉，此时S1=”计算语言学”；</li>
<li>S1不为空，于是从S1左边取出候选子串W=”计算语言学”；</li>
<li>查词表，“计算语言学”在词表中，将W加入到S2中，S2=“计算语言学/ 课程/ 有/ 意思/”，并将W从S1中去掉，此时S1=””；</li>
<li>S1为空，输出S2作为分词结果，分词过程结束。</li>
</ol>
<p>至于怎么实现,<a href="http://yangshangchuan.iteye.com/blog/2031813">中文分词算法之基于词典的正向最大匹配算法</a>一文中对针对JAVA的实现有非常详尽的性能分析,其实吧,个人觉得算法无非是在时间和空间间的权衡,对Hash式存储结构而言,一般来讲,空间开销是很大的,而时间上可以做的很好;对于类似于Trie树的数据结构,在某种程度上能节省一定的空间,但肯定比Hash类数据结构慢点。这里我们就不纠结数据结构和性能的差异了,我们使用STL set<sup id="sf-zi-ran-yu-yan-chu-li-xu-zhang-wo-ai-zi-ran-yu-yan-chu-li-1-back"><a class="simple-footnote" href="#sf-zi-ran-yu-yan-chu-li-xu-zhang-wo-ai-zi-ran-yu-yan-chu-li-1" title="STL中set的简单学习">1</a></sup>实现上述功能。</p>
<p>以下给出逆向最长匹配算法C++源码(<strong>代码中词典的初始化只用了几个词,实际中可从词表文件中读取并构造一个词典,此处代码只是为了演示算法框架</strong>):</p>
<div class="highlight"><pre><span class="vi">#include</span> <span class="o">&lt;</span><span class="nx">iostream</span><span class="o">&gt;</span>
<span class="vi">#include</span> <span class="o">&lt;</span><span class="nb">set</span><span class="o">&gt;</span>

<span class="nx">using</span> <span class="nx">namespace</span> <span class="nx">std</span><span class="p">;</span>

<span class="cm">/**</span>
<span class="cm"> *A simple inverse match algorithm</span>
<span class="cm"> *@author:qingyuanxingsi</span>
<span class="cm"> *@date:2014-05-04</span>
<span class="cm"> *@version:1.0</span>
<span class="cm"> */</span>
<span class="nx">int</span> <span class="nx">main</span><span class="p">(</span><span class="nx">int</span> <span class="nx">argc</span><span class="p">,</span> <span class="nx">char</span> <span class="o">**</span><span class="nx">argv</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">//Max word length</span>
    <span class="nx">const</span> <span class="nx">int</span> <span class="n">max_len</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>
    <span class="nx">const</span> <span class="kt">string</span> <span class="n">split_sequence</span> <span class="o">=</span> <span class="s2">"/"</span><span class="p">;</span>
    <span class="nx">const</span> <span class="kt">string</span> <span class="n">to_split</span> <span class="o">=</span> <span class="s2">"计算语言学真有意思啊"</span><span class="p">;</span>
    <span class="nb">set</span><span class="o">&lt;</span><span class="kt">string</span><span class="o">&gt;</span> <span class="nx">dict</span><span class="p">;</span>
    <span class="c1">//Initialize the dict</span>
    <span class="nx">dict.insert</span><span class="p">(</span><span class="s2">"计算语言学"</span><span class="p">);</span>
    <span class="nx">dict.insert</span><span class="p">(</span><span class="s2">"意思"</span><span class="p">);</span>
    <span class="c1">//Split the Chinese Sequence</span>
    <span class="nx">int</span> <span class="n">tail</span> <span class="o">=</span> <span class="nx">to_split.length</span><span class="p">();</span>
    <span class="nb">for</span><span class="p">(</span><span class="nx">int</span> <span class="n">i</span><span class="o">=</span><span class="nx">max_len</span><span class="p">;</span><span class="nx">i</span><span class="o">&gt;</span><span class="mi">0</span><span class="o">&amp;&amp;</span><span class="nx">tail</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">;</span><span class="nx">i</span><span class="o">--</span><span class="p">){</span>
      <span class="kt">string</span> <span class="n">temp</span> <span class="o">=</span> <span class="nx">to_split.substr</span><span class="p">(</span><span class="nx">tail</span><span class="na">-i</span><span class="p">,</span><span class="nx">i</span><span class="p">);</span>
      <span class="c1">//If single word</span>
      <span class="k">if</span><span class="p">(</span><span class="nx">temp.length</span><span class="p">()</span><span class="o">==</span><span class="mi">1</span><span class="p">){</span>
        <span class="nx">cout</span><span class="o">&lt;&lt;</span><span class="nx">split_sequence</span><span class="o">&lt;&lt;</span><span class="nx">temp</span><span class="o">&lt;&lt;</span><span class="nx">endl</span><span class="p">;</span>
        <span class="nx">tail</span> <span class="o">-=</span><span class="mi">1</span><span class="p">;</span>
        <span class="k">if</span><span class="p">(</span><span class="nx">tail</span><span class="o">&lt;</span><span class="nx">max_len</span><span class="p">){</span>
            <span class="n">i</span> <span class="o">=</span> <span class="nx">tail</span><span class="o">+</span><span class="mi">1</span><span class="p">;</span>
        <span class="p">}</span>
        <span class="k">else</span><span class="p">{</span>
            <span class="n">i</span> <span class="o">=</span> <span class="nx">max_len</span><span class="o">+</span><span class="mi">1</span><span class="p">;</span>
        <span class="p">}</span>
      <span class="p">}</span>
      <span class="k">if</span><span class="p">(</span><span class="nx">dict.find</span><span class="p">(</span><span class="nx">temp</span><span class="p">)</span><span class="o">!=</span><span class="nx">dict.end</span><span class="p">()){</span>
        <span class="nx">cout</span><span class="o">&lt;&lt;</span><span class="nx">split_sequence</span><span class="o">&lt;&lt;</span><span class="nx">temp</span><span class="o">&lt;&lt;</span><span class="nx">endl</span><span class="p">;</span>
        <span class="nx">tail</span> <span class="o">-=</span><span class="nx">i</span><span class="p">;</span>
        <span class="k">if</span><span class="p">(</span><span class="nx">tail</span><span class="o">&lt;</span><span class="nx">max_len</span><span class="p">){</span>
            <span class="n">i</span> <span class="o">=</span> <span class="nx">tail</span><span class="o">+</span><span class="mi">1</span><span class="p">;</span>
        <span class="p">}</span>
        <span class="k">else</span><span class="p">{</span>
            <span class="n">i</span> <span class="o">=</span> <span class="nx">max_len</span><span class="o">+</span><span class="mi">1</span><span class="p">;</span>
        <span class="p">}</span>
      <span class="p">}</span>
    <span class="p">}</span>  
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>


<blockquote>
<p>NOTE:这种机械的分词方法实际上是远远满足不了我们的需要的,对于某些特定的句子不管采用正向最长匹配还是逆向最长匹配都会产生错误切分。比如说<strong>"结婚的和尚未结婚的"</strong>,采用正向最长匹配就得不到正确的分词结果,逆向最长匹配也类同。类似的分词方法还有<strong>最小词数法</strong>等。</p>
</blockquote>
<p>基于以上简单的中文分词算法，很多学者进行了改进,我爱自然语言网站上介绍了一个叫MMSEG的系统,个人不是很感兴趣,有兴趣的同学可参考如下链接:</p>
<ul>
<li><a href="http://www.52nlp.cn/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E5%85%A5%E9%97%A8%E4%B9%8B%E6%9C%80%E5%A4%A7%E5%8C%B9%E9%85%8D%E6%B3%95%E6%89%A9%E5%B1%951">中文分词入门之最大匹配法扩展1</a></li>
<li><a href="http://www.52nlp.cn/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E5%85%A5%E9%97%A8%E4%B9%8B%E6%9C%80%E5%A4%A7%E5%8C%B9%E9%85%8D%E6%B3%95%E6%89%A9%E5%B1%952">中文分词入门之最大匹配法扩展2</a></li>
<li><a href="http://www.52nlp.cn/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E5%85%A5%E9%97%A8%E4%B9%8B%E7%AF%87%E5%A4%96">中文分词入门之篇外</a></li>
</ul>
<h2>基于字标注的中文分词<sup id="sf-zi-ran-yu-yan-chu-li-xu-zhang-wo-ai-zi-ran-yu-yan-chu-li-2-back"><a class="simple-footnote" href="#sf-zi-ran-yu-yan-chu-li-xu-zhang-wo-ai-zi-ran-yu-yan-chu-li-2" title="本部分更多细节请参考我爱自然语言处理博客!">2</a></sup></h2>
<p>以往的分词方法，无论是基于规则的还是基于统计的，一般都依赖于一个事先编制的词表(词典)。自动分词过程就是通过词表和相关信息来做出词语切分的决策。与此相反，基于字标注的分词方法实际上是构词方法。即把分词过程视为字在字串中的标注问题。由于每个字在构造一个特定的词语时都占据着一个确定的构词位置(即词位)，假如规定每个字最多只有四个构词位置：即B(词首)，M (词中)，E(词尾)和S(单独成词)，那么下面句子(甲)的分词结果就可以直接表示成如(乙)所示的逐字标注形式：</p>
<blockquote>
<p>(甲)分词结果：／上海／计划／N／本／世纪／末／实现／人均／国内／生产／总值／五千美元／。</p>
<p>(乙)字标注形式：上/B 海／E 计／B 划／E N／S 本／s 世／B 纪／E 末／S 实／B 现／E 人／B 均／E 国／B 内／E生／B产／E总／B值／E 五／B千／M 美／M 元／E 。／S</p>
</blockquote>
<p>首先需要说明，这里说到的“字”不只限于汉字。考虑到中文真实文本中不可避免地会包含一定数量的非汉字字符，本文所说的“字”，也包括外文字母、阿拉伯数字和标点符号等字符。所有这些字符都是构词的基本单元。当然，汉字依然是这个单元集合中数量最多的一类字符。</p>
<p>把分词过程视为字的标注问题的一个重要优势在于，<strong>它能够平衡地看待词表词和未登录词的识别问题</strong>。在这种分词技术中，文本中的词表词和未登录词都是用统一的字标注过程来实现的。在学习架构上，既可以不必专门强调词表词信息，也不用专门设计特定的未登录词(如人名、地名、机构名)识别模块。这使得分词系统的设计大大简化。在字标注过程中，所有的字根据预定义的特征进行词位特性的学习，获得一个概率模型。然后，在待分字串上，根据字与字之间的结合紧密程度，得到一个词位的标注结果。最后，根据词位定义直接获得最终的分词结果。总而言之，在这样一个分词过程中，分词成为字重组的简单过程。然而这一简单处理带来的分词结果却是令人满意的。</p>
<p>在<a href="http://www.52nlp.cn/two-innovative-ideas-in-natural-language-processing-area">《自然语言处理领域的两种创新观念》</a>中，张俊林博士谈了两种创新模式：<strong>一种创新是研究模式的颠覆，另外一种创新是应用创新</strong>，前者需要NLP领域出现爱因斯坦式的革新人物，后者则是强调用同样的核心技术做不一样的应用。</p>
<p>在自然语言处理领域，多数创新都属于后者，譬如统计机器翻译，Brown就是学习和借鉴了贾里尼克将语音识别看成通信问题的思想，将信源信道模型应用到了机器翻译之中，从而开辟了SMT这一全新领域。而Nianwen Xue将词性标注的思想应用到中文分词领域，成就了字标注的中文分词方法（Chinese Word Segmentation as Character Tagging），同样取得了巨大的成功。</p>
<p>既然基于字标注的中文分词方法是将中文分词当作词性标注的问题来对待，那么就必须有标注对象和标注集了。形象一点，从这个方法的命名上我们就可以推断出它的标注是基本的汉字（还包括一定数量的非汉字字符），而标注集则比较灵活，这些标注集都是依据汉字在汉语词中的位置设计的，最简单的是2-tag，譬如将词首标记设计为B，而将词的其他位置标记设计为I，那么“中国”就可以标记为“中/B 国/I”，“海南岛”则可以标记为“海/B 南/I 岛/I”，相应地，对于如下分好词的句子：</p>
<div class="highlight"><pre><span class="err">瓦西里斯</span> <span class="err">的</span> <span class="err">船只</span> <span class="err">中</span> <span class="err">有</span> <span class="mi">40</span><span class="o">%</span> <span class="err">驶</span> <span class="err">向</span> <span class="err">远东</span> <span class="err">，</span> <span class="err">每个</span> <span class="err">月</span> <span class="err">几乎</span> <span class="err">都</span> <span class="err">有</span> <span class="err">两三条</span> <span class="err">船</span> <span class="err">停靠</span> <span class="err">中国</span> <span class="err">港口</span> <span class="err">。</span>
</pre></div>


<p>基于2-tag(B,I)的标注就是：</p>
<div class="highlight"><pre><span class="err">瓦</span><span class="o">/</span><span class="n">B</span> <span class="err">西</span><span class="o">/</span><span class="n">I</span> <span class="err">里</span><span class="o">/</span><span class="n">I</span> <span class="err">斯</span><span class="o">/</span><span class="n">I</span> <span class="err">的</span><span class="o">/</span><span class="n">B</span> <span class="err">船</span><span class="o">/</span><span class="n">B</span> <span class="err">只</span><span class="o">/</span><span class="n">I</span> <span class="err">中</span><span class="o">/</span><span class="n">B</span> <span class="err">有</span><span class="o">/</span><span class="n">B</span> <span class="err">４</span><span class="o">/</span><span class="n">B</span> <span class="err">０</span><span class="o">/</span><span class="n">I</span> <span class="err">％</span><span class="o">/</span><span class="n">I</span> <span class="err">驶</span><span class="o">/</span><span class="n">B</span> <span class="err">向</span><span class="o">/</span><span class="n">B</span> <span class="err">远</span><span class="o">/</span><span class="n">B</span> <span class="err">东</span><span class="o">/</span><span class="n">I</span> <span class="err">，</span><span class="o">/</span><span class="n">B</span> <span class="err">每</span><span class="o">/</span><span class="n">B</span> <span class="err">个</span><span class="o">/</span><span class="n">I</span> <span class="err">月</span><span class="o">/</span><span class="n">B</span> <span class="err">几</span><span class="o">/</span><span class="n">B</span> <span class="err">乎</span><span class="o">/</span><span class="n">I</span> <span class="err">都</span><span class="o">/</span><span class="n">B</span> <span class="err">有</span><span class="o">/</span><span class="n">B</span> <span class="err">两</span><span class="o">/</span><span class="n">B</span> <span class="err">三</span><span class="o">/</span><span class="n">I</span> <span class="err">条</span><span class="o">/</span><span class="n">I</span> <span class="err">船</span><span class="o">/</span><span class="n">B</span> <span class="err">停</span><span class="o">/</span><span class="n">B</span> <span class="err">靠</span><span class="o">/</span><span class="n">I</span> <span class="err">中</span><span class="o">/</span><span class="n">B</span> <span class="err">国</span><span class="o">/</span><span class="n">I</span> <span class="err">港</span><span class="o">/</span><span class="n">B</span> <span class="err">口</span><span class="o">/</span><span class="n">I</span> <span class="err">。</span><span class="o">/</span><span class="n">B</span>
</pre></div>


<p>除了2-tag，还有4-tag、6-tag等，都是依据字在词中的位置设计的，本文主要目的是从实践的角度介绍基于字标注的中文分词方法设计，以达到抛砖引玉的作用，因此我们仅选用2-tag（B，I）标注集进行实验说明。有了标注对象和标注集，那么又如何进行中文分词呢？因为字标注本质上是采用POS Tagging的思想,只不过要TAG的基本单元现在变成字了而已,因此我们可以这样做:</p>
<ul>
<li>获取已分词语料,将其转化为字的形式并采用某种标注集根据分词信息对其进行标注;</li>
<li>将得到的语料作为训练集输入到最大熵模型或者HMM模型中进行训练(<strong>可以使用Citar</strong>);</li>
<li>利用训练后模型对未分词语料进行字标注,最后还原成分词结果即可。</li>
</ul>
<blockquote>
<p>NOTE:利用现有开源工具时,如果能够构建适用于中文字标注的特征集合,然后再进行训练,可能会取得更好的结果。</p>
</blockquote>
<h1>无约束最优化</h1>
<hr>
<p>当看到这个部分的时候,一切都开始变得有意思起来了,好吧,言归正传。</p>
<p>本部分主要介绍无约束最优化问题，同时初步介绍解该类问题目前常用的一种算法即<strong>Quasi-Newton Method</strong>(拟牛顿法)。在介绍无约束最优化问题之前，我们首先会从直观上引入无约束最优化的概念，并在此基础上引入解这类问题的两个重要概念：步长和方向。由步长的选择引入重要概念line search，由方向的选择引入重要概念Quasi-Newton Method。因此本部分主要分为以下几个部分：无约束最优化问题引入，Line Search ，Quasi-Newton Method和算法总结。</p>
<h2>无约束最优化</h2>
<p>对无约束最优化不熟悉的读者也许要问，什么是无约束最优化。这里以一个例子来说明该问题。</p>
<p><img alt="quasi_method_1" src="http://i1302.photobucket.com/albums/ag136/qingyuanxingsi/blog/quasi_method_1_zps368407e4.png"></p>
<p>上图所示为一元函数$f(x)$的图像，无约束最优化问题，即不对定义域或值域做任何限制的情况下，求解函数$f(x)$的最小值，上面显示两个最小值点：一个为全局最小值点，另一个为局部最小值点。受限于算法复杂度等问题，目前大部分无约束最优化算法只能保证求取局部最小值点。这时读者不免要问，既然只能求取局部最小值点，那为什么这类算法还能应用呢。这是因为实际应用中，许多情形被抽象为函数形式后均为凸函数，对于凸函数来说局部最小值点即为全局最小值点，因此只要能求得这类函数的一个最小值点，该点一定为全局最小值点。</p>
<p>理解了上面的无约束最优化问题之后，我们就可以开始介绍无约束最优化的求解过程了，对于无约束最优化的求解首先我们需要选择一个初始点$x_0$，如下所示：</p>
<p><img alt="quasi_method_2" src="http://i1302.photobucket.com/albums/ag136/qingyuanxingsi/blog/quasi_method_2_zps6e717209.png"></p>
<p>初始点选择好之后，就可以按照各种不同的无约束最优化求解算法，求解最小值点了。求解过程中主要涉及两个概念，即从初始点开始沿“哪个方向”以及“走多远”到达下一个点处。所谓“走多远”即之前提的“步长”的概念，“哪个方向”即方向概念。</p>
<h2>Line Search</h2>
<p>Line search主要用于解决之前提到的步长的概念，即方向确定好之后，需要确定从当前点$x_k$沿着该方向走多远，以便走到下一个合适的点$x_{k+1}$。若用$p_k$代表从第$k$个点走向第$k+1$点的方向，$x_k$代表当前点，$x_k+1$代表下一个点，$a_k$代表步长，则存在如下的等式：</p>
<p>\begin{equation}
x_{k+1} = x_k + a_k \times p_k
\end{equation}</p>
<p>这里简要介绍一下$p_k$，大部分line search方法要求$p_k$为下降方向，即从当前点沿着$p_k$方向移动后导致函数值减少。由于目标是求取一个函数的最小值，因此最优的情况是求取沿$p_k$方向满足$f(x_{k+1})$为全局最小的$a_k$值，可用下式表示为：</p>
<p>\begin{equation}
\phi(a_k) = f(x_{k+1}) = f(x_k + a_k \times p_k) 
\end{equation}</p>
<p><img alt="quasi_method_3" src="http://i1302.photobucket.com/albums/ag136/qingyuanxingsi/blog/quasi_method_3_zps68d36744.png"></p>
<p>由于直接求取满足$\phi(a_k)$为全局最小值的$a_k$涉及到大量$f(x_k + a_k \times p_k)$的计算，若从求导角度计算最小值，还会涉及到$\bigtriangledown f_{k+1}$的计算，计算量较大。因此从计算量角度考虑，可以采用如下较为折中的策略。</p>
<p>方向确定好之后，每一步的line Search主要涉及两个问题：</p>
<ul>
<li>什么样的$a_k$是合理的;</li>
<li>如何选择$a_k$的长度。下面将沿这两个面展开讨论，首先讨论“什么样的$a_k$是合理的”，确定了该问题之后，我们就可以在此基础上选择$a_k$了。</li>
</ul>
<h3>合理性讨论</h3>
<p>如下将要讨论关于$a_k$需要满足的两个条件，当$a_k$满足这两个条件后，就可以认为从$x_k$点移动到$x_{k+1}$点的步长已经确定下来了。第一个条件为<strong>sufficient decrease condition</strong>，从直观角度来看，该条件主要要用保证$x_{k+1}$点的函数值要小于$x_k$点的函数值，满足该条件后，才有全局收敛 的可能性。第二个条件为<strong>curvature condition</strong>，从直观角度来看，该条件主要用于保证$x_k$点经过步长$a_k$的移动到达$x_{k+1}$后，$\bigtriangledown f_{k+1}$小于$\bigtriangledown f_k$。</p>
<h4>Sufficient decrease condition</h4>
<p>$a_k$的选择一定要使得函数值满足<strong>sufficient decrease condition</strong>，该条件可以用如下不等式描述：　　 　　</p>
<p>\begin{equation}
f(x_{k+1}) \leq f(x_k) + c_1 \times a_k \bigtriangledown f(x_k)^Tp_k
\end{equation}</p>
<p>更进一步地,我们有：</p>
<p>\begin{equation}
f(x_k + a_k p_k) \leq f(x_k) + c_1 \times a_k \bigtriangledown f(x_k)^Tp_k
\end{equation}</p>
<p>其中$c_1$为常量，需满足$0&lt; c_1 &lt; 1$，一般取$c_1$为$10^{-4}$.</p>
<blockquote>
<p>NOTE:Quasi-Newton Method中要求$0&lt; c_1&lt; 0.5$).</p>
</blockquote>
<p>当$p_k$为函数下降方向时，有：　　　　　 </p>
<p>\begin{equation}
\bigtriangledown f(k)^T p(k) &lt; 0
\end{equation}</p>
<blockquote>
<p><strong>NOTE:WHY?求大神指教!</strong></p>
</blockquote>
<p>因此根据最初的不等式，即要求：　</p>
<p>\begin{equation}
f(x_{k+1}) ＜ f(x_k)
\end{equation} 　　　　　</p>
<p>从图形角度看，函数位于第$k$点时，以上各参数中只有$a_k$为变量，其他均为常量，因此最初条件不等式可以重写为：</p>
<p>\begin{equation}
\phi(a_k) \leq l(a_k)
\end{equation}</p>
<p>其中,$l(a_k)$为最初不等式右边部分,图形化描述如下：</p>
<p><img alt="OPT_1" src="http://i1302.photobucket.com/albums/ag136/qingyuanxingsi/blog/opt2_4_zps2271e1ed.png"></p>
<p>因此只要步长$a_k$的选择使得函数$\phi(a_k)$位于acceptable区间，就满足<strong>Sufficient decrease condition</strong>。</p>
<h4>Curvature condition</h4>
<p>$a_k$的选择一定要使得函数梯度值满足<strong>Curvature condition</strong>，该条件可以用如下不等式描述：　　</p>
<p>\begin{equation}
\bigtriangledown f(x_k+a_kp_k)^Tp(k) \geq c_2 \bigtriangledown f(x_k)^T p(k)
\end{equation}</p>
<p>即为:</p>
<p>\begin{equation}
\bigtriangledown f(x_{k+1})^Tp(k) \geq c_2 \bigtriangledown f(x_k)^T p(k)
\end{equation}</p>
<p>其中$c_2$为常量，需满足$0&lt;c_1&lt;c_2&lt;1$，一般取$c_2$为$0.9$.</p>
<p>当$p_k$为函数下降方向时，有：　　　　　</p>
<p>\begin{equation}
\bigtriangledown f(x_k)p_k &lt;0 
\end{equation}</p>
<p>Method中的LBFGS算法到这里总算初步介绍完了，不过这里笔者要承认的是这篇文档省略了许多内容，包括算法收敛性的证明以及收敛速度证明等许多内容。因此读者若希望对这一块有一个更深入的认识可以参考以下两本书：</p>
<ul>
<li>Numerical Methods for Unconstrained Optimization and Nonlinear Equations（J.E. Dennis Jr. Robert B. Schnabel）</li>
<li>Numerical Optimization（Jorge Nocedal Stephen J. Wright）</li>
</ul>
<p>同时我想引用一下侯捷老师的话：　　</p>
<blockquote>
<p>大哉问。学习需要明师。但明师可遇不可求，所以退而求其次你需要好书，并尽早建立自修的基础。迷时师渡，悟了自渡，寻好书看好书，就是你的自渡法门。切记，徒学不足以自行，计算机是实作性很强的一门科技，你一定要动手做，最忌讳眼高手低。学而不思则罔，思而不学则殆，一定要思考、沉淀、整理。</p>
</blockquote>
<p>因此这里附上一个我阅读后感觉代码还比较美观的LBFGS实现（C++):http://www.chokkan.org/software/liblbfgs/(Naoaki Okazaki).</p>
<h1>资源集锦</h1>
<hr>
<ul>
<li><a href="http://clair.eecs.umich.edu/aan/index.php">ACL Anthology Network</a></li>
<li><a href="https://www.ldc.upenn.edu/">LDC (Linguistic Data Consortium)</a></li>
</ul>
<blockquote>
<p><strong>TODO Board:</strong></p>
<ul>
<li><em>TBL</em>(<strong>参考《自然语言处理综论》第8章</strong>)</li>
<li><strong>最大熵求解算法IIS等</strong></li>
</ul>
</blockquote><script type="text/javascript">
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
</script>
<ol class="simple-footnotes"><li id="sf-zi-ran-yu-yan-chu-li-xu-zhang-wo-ai-zi-ran-yu-yan-chu-li-1"><a href="http://www.cppblog.com/shongbee2/archive/2009/04/05/79011.html">STL中set的简单学习</a> <a class="simple-footnote-back" href="#sf-zi-ran-yu-yan-chu-li-xu-zhang-wo-ai-zi-ran-yu-yan-chu-li-1-back">↩</a></li><li id="sf-zi-ran-yu-yan-chu-li-xu-zhang-wo-ai-zi-ran-yu-yan-chu-li-2">本部分更多细节请参考我爱自然语言处理博客! <a class="simple-footnote-back" href="#sf-zi-ran-yu-yan-chu-li-xu-zhang-wo-ai-zi-ran-yu-yan-chu-li-2-back">↩</a></li></ol> 
	<a class="btn btn-mini xsmall" href="../zi-ran-yu-yan-chu-li-xu-zhang-wo-ai-zi-ran-yu-yan-chu-li.html">
          <i class="icon-comment"></i> Comment </a>
	<hr />
      </div>
      
    </div>
    

 
        



    <div class='row-fluid'>
      <div class='article-title span9'> 
        <a href="../xiao-xiao-shou-cang-jia-chi-xu-geng-xin-zhong.html"><h1>小小收藏夹[持续更新中]</h1></a>
      </div>
    </div>
    <div class="row-fluid">
      <div class="span2">
<p>日 04 五月 2014 </p>

<p style="text-align: left;">
Filed under <a href="../category/pearls.html">Pearls</a>
</p>
<p style="text-align: left;">
 
    Tags <a href="../tag/suan-fa.html">算法</a> <a href="../tag/fun.html">Fun</a> <a href="../tag/staff.html">Staff</a> <a href="../tag/shou-cang-jia.html">收藏夹</a> <a href="../tag/bloom-filter.html">Bloom Filter</a> <a href="../tag/b-trees.html">B Trees</a> <a href="../tag/data-structure.html">Data Structure</a> <a href="../tag/algorithm.html">Algorithm</a> <a href="../tag/pgm.html">PGM</a> </p>
<p>
</p>
      </div>
      <div class="summary span8">
	<p>主要收集一些还不错的东东(持续更新)。</p> 
	<a class="btn btn-mini xsmall" href="../xiao-xiao-shou-cang-jia-chi-xu-geng-xin-zhong.html">
          <i class="icon-plus-sign"></i> Read More </a>
	<hr />
      </div>
      
    </div>
      

 
        



    <div class='row-fluid'>
      <div class='article-title span9'> 
        <a href="../ji-qi-xue-xi-shi-yi-iida-za-hui.html"><h1>机器学习拾遗(II):大杂烩</h1></a>
      </div>
    </div>
    <div class="row-fluid">
      <div class="span2">
<p>五 02 五月 2014 </p>

<p style="text-align: left;">
Filed under <a href="../category/notes.html">Notes</a>
</p>
<p style="text-align: left;">
 
    Tags <a href="../tag/machine-learning.html">Machine Learning</a> <a href="../tag/gaussian-models.html">Gaussian Models</a> <a href="../tag/linear-models.html">Linear Models</a> <a href="../tag/notes.html">Notes</a> </p>
<p>
</p>
      </div>
      <div class="summary span8">
	<p>阅读<em>Machine Learning:A Probabilistic Perspective</em>一书关于上述部分的若干章节并对之前未理解的部分内容进行梳理。</p> 
	<a class="btn btn-mini xsmall" href="../ji-qi-xue-xi-shi-yi-iida-za-hui.html">
          <i class="icon-plus-sign"></i> Read More </a>
	<hr />
      </div>
      
    </div>
      

 
        



    <div class='row-fluid'>
      <div class='article-title span9'> 
        <a href="../dang-zui-jin-lin-yu-dao-lsh.html"><h1>当最近邻遇到LSH</h1></a>
      </div>
    </div>
    <div class="row-fluid">
      <div class="span2">
<p>四 01 五月 2014 </p>

<p style="text-align: left;">
Filed under <a href="../category/pearls.html">Pearls</a>
</p>
<p style="text-align: left;">
 
    Tags <a href="../tag/suan-fa.html">算法</a> <a href="../tag/algorithm.html">Algorithm</a> <a href="../tag/lsh.html">LSH</a> <a href="../tag/ju-bu-min-gan-ha-xi-suan-fa.html">局部敏感哈希算法</a> </p>
<p>
</p>
      </div>
      <div class="summary span8">
	<p>本文主要介绍局部敏感哈希算法。</p> 
	<a class="btn btn-mini xsmall" href="../dang-zui-jin-lin-yu-dao-lsh.html">
          <i class="icon-plus-sign"></i> Read More </a>
	<hr />
      </div>
      
    </div>
      

 
        



    <div class='row-fluid'>
      <div class='article-title span9'> 
        <a href="../ji-qi-xue-xi-shi-yi-igai-lu-tu-mo-xing-dai-xu.html"><h1>机器学习拾遗(I):概率图模型[待续]</h1></a>
      </div>
    </div>
    <div class="row-fluid">
      <div class="span2">
<p>四 01 五月 2014 </p>

<p style="text-align: left;">
Filed under <a href="../category/notes.html">Notes</a>
</p>
<p style="text-align: left;">
 
    Tags <a href="../tag/machine-learning.html">Machine Learning</a> <a href="../tag/graphical-models.html">Graphical Models</a> <a href="../tag/notes.html">Notes</a> </p>
<p>
</p>
      </div>
      <div class="summary span8">
	<p>阅读<em>Machine Learning:A Probabilistic Perspective</em>一书第十章并记录之前看PGM公开课时漏掉的一些知识点。</p> 
	<a class="btn btn-mini xsmall" href="../ji-qi-xue-xi-shi-yi-igai-lu-tu-mo-xing-dai-xu.html">
          <i class="icon-plus-sign"></i> Read More </a>
	<hr />
      </div>
      
    </div>
      
<div class="pagination">
<ul>
    <li class="prev disabled"><a href="#">&larr; Previous</a></li>

    <li class="active"><a href="../author/qingyuanxingsi.html">1</a></li>
    <li class=""><a href="../author/qingyuanxingsi2.html">2</a></li>
    <li class=""><a href="../author/qingyuanxingsi3.html">3</a></li>
    <li class=""><a href="../author/qingyuanxingsi4.html">4</a></li>

    <li class="next"><a href="../author/qingyuanxingsi2.html">Next &rarr;</a></li>

</ul>
</div>
 
  
        </div>
        
        
    </div>     </div> </div>

<!--footer-->
<div class="container">
  <div class="well" style="background-color: #E9EFF6">
    <div id="blog-footer">
      <div class="row-fluid">
	<div class="social span2" align="center" id="socialist">
	  <ul class="nav nav-list">
	    <li class="nav-header">
	      Social
	    </li>
	    <li><a href="https://github.com/qingyuanxingsi"><i class="icon-Github" style="color: #1f334b"></i>Github</a></li>

	  </ul>
	</div>
        <div class="links span2" align="center">
          <ul class="nav nav-list">
            <li class="nav-header"> 
              Links
            </li>
            
            <li><a href="http://freemind.pluskid.org">Pluskid</a></li>
            <li><a href="https://github.com/julycoding/The-Art-Of-Programming-By-July">结构之法 算法之道</a></li>
            <li><a href="http://www.nosqlnotes.net/">NOSQL Notes</a></li>
            <li><a href="http://diaorui.net/">数学之美</a></li>
            <li><a href="http://licstar.net/">让博客飞(A BLOG WITH FUN)</a></li>
            <li><a href="http://www.xperseverance.net/blogs/">持之以恒</a></li>
            <li><a href="http://ibillxia.github.io/">Bill's Blog</a></li>
          </ul>
        </div>
	<div class="site-nav span2" align="center">
          <ul class="nav nav-list" id="site-links">
            <li class="nav-header"> 
              Site
            </li>
            <li><a href=".."><i class="icon-home" style="color: #1f334b">
                </i>Home</a></li>
            <li><a href="../archives.html"><i class="icon-list" style="color: #1f334b">
                </i>Archives</a></li>
	    <li><a href="../tags.html"><i class="icon-tags" style="color: #1f334b">
                </i>Tags</a></li>
	    
            <li><a href="../" rel="alternate">
                <i class="icon-rss-sign" style="color: #1f334b"></i>
                Atom Feed</a></li>
	  </ul>

        </div>

      </div> <!--end of fluid row-->
    </div> <!--end of blog-footer-->
    <hr />
    <p align="center"><a href="..">苹果的味道</a>
      &copy; qingyuanxingsi
    Powered by <a href="github.com/getpelican/pelican">Pelican</a> and
        <a href="https://twitter.github.com/bootstrap">Twitter Bootstrap</a>. 
        Icons by <a href="http://fortawesome.github.com/Font-Awesome">Font Awesome</a> and 
        <a href="http://gregoryloucas.github.com/Font-Awesome-More">Font Awesome More</a></p>

  </div> <!--end of well -->
</div> <!--end of container -->

<!--/footer-->
<script src="//ajax.googleapis.com/ajax/libs/jquery/1.8.3/jquery.min.js"></script>
<script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.2.2/js/bootstrap.min.js"></script>


<script>var _gaq=[['_setAccount','UA-48582273-1'],['_trackPageview']];(function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];g.src='//www.google-analytics.com/ga.js';s.parentNode.insertBefore(g,s)}(document,'script'))</script>

</body>
</html>