<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>机器学习系列(I):决策树算法</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="qingyuanxingsi">

    <!-- Le styles -->
    <link rel="stylesheet" href="/theme/css/bootstrap.min.css" type="text/css" />
    <style type="text/css">
      body {
        padding-top: 60px;
        padding-bottom: 40px;
      }
      .sidebar-nav {
        padding: 9px 0;
      }
      .tag-1 {
        font-size: 13pt;
      }
      .tag-2 {
        font-size: 10pt;
      }
      .tag-2 {
        font-size: 8pt;
      }
      .tag-4 {
        font-size: 6pt;
     }
    </style>
    <link href="/theme/css/bootstrap-responsive.min.css" rel="stylesheet">
        <link href="/theme/css/font-awesome.css" rel="stylesheet">

    <link href="/theme/css/pygments.css" rel="stylesheet">

    <!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script src="//html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <!-- Le fav and touch icons -->
    <link rel="shortcut icon" href="/theme/images/favicon.ico">
    <link rel="apple-touch-icon" href="/theme/images/apple-touch-icon.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/theme/images/apple-touch-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/theme/images/apple-touch-icon-114x114.png">

    <link href="/" type="application/atom+xml" rel="alternate" title="Doodle World ATOM Feed" />

  </head>

  <body>

    <div class="navbar navbar-fixed-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="/index.html">Doodle World </a>
          <div class="nav-collapse">
            <ul class="nav">
                          <li class="divider-vertical"></li>
                  <li class="active">
                    <a href="/category/machine-learning.html">
						<i class="icon-folder-open icon-large"></i>Machine Learning
					</a>
                  </li>

                          <ul class="nav pull-right">
                                <li><a href="/archives.html"><i class="icon-th-list"></i>Archives</a></li>
                          </ul>

            </ul>
            <!--<p class="navbar-text pull-right">Logged in as <a href="#">username</a></p>-->
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row">
        <div class="span9" id="content">
<section id="content">
        <article>
                <header>
                        <h1>
                                <a href=""
                                        rel="bookmark"
                                        title="Permalink to 机器学习系列(I):决策树算法">
                                        机器学习系列(I):决策树算法
                                </a>
                        </h1>
                </header>
                <div class="entry-content">
                <div class="well">
<footer class="post-info">
<span class="label">Date</span>
<abbr class="published" title="2013-03-03T00:00:00">
        <i class="icon-calendar"></i>日 03 三月 2013
</abbr>
<span class="label">By</span>
<a href="/author/qingyuanxingsi.html"><i class="icon-user"></i>qingyuanxingsi</a>
<span class="label">Category</span>
<a href="/category/machine-learning.html"><i class="icon-folder-open"></i>Machine Learning</a>.


<span class="label">Tags</span>
	<a href="/tag/machine-learning.html"><i class="icon-tag"></i>Machine Learning</a>
</footer><!-- /.post-info -->                </div>
                <h1>写在前面</h1>
<hr />
<p>好吧，今天我的博客在线下默默地开张了，花了好长时间才把中文显示的问题解决。言归正传，之所以开通这个博客，原因有二：</p>
<ul>
<li>对已经学过的知识进行梳理，保证学习过程的稳步前进；</li>
<li>敦促自己每周有一定的学习目标,以更好地推进自己的学习.</li>
</ul>
<p>关于这个博客其他的我就不说了，如果你觉得这个博客有点用，你愿意花点时间看看，我会灰常感激滴。如果你觉得这个博客没什么用，直接忽略就好。此外，这篇博客所有内容均host在Github上，本着分享，协作的精神，如果你愿意而且有时间欢迎投稿至qingyuanxingsi@163.com,I would be much glad to receive your mails.</p>
<h1>简介</h1>
<hr />
<h2>二三闲话</h2>
<p>这是本博客的第一篇博文，也是第一篇关于机器学习方面的博文，因此我想扯些闲话。就我而言，我觉得所有的机器学习算法并不只是模型本身那么简单，背后其实还有一些别的东西，从某种角度来说，它们也是模型的创立者认识世界的方式。</p>
<p>举贝叶斯为例，从他的模型中可能能推断出他也许认为万物皆有联系，所有的事物都不是孤立的，都是相互联系，相互影响的。另，我经常听到人们抱怨这个世界不公平，这个世界并不是他们想要的那种模样；或者说自从多年前姚晨和凌潇肃离婚之后，好多人都不再相信爱情了(just a joke）。从这两个例子中，也许我们能看到另外一些
东西，我们很久很久以前都对这个世界有一些先入为主的认识(<strong>prior</strong>),我们愿意相信这个世界是公平的，爱情是非常美好的一件事。后来，慢慢的我们发现这个世界其实有很多不公平的事，我们发现这个世界里的爱情没我们想象的那么美好，我们看到了一些真实世界实实在在存在的事情(<strong>data</strong>),于是我们对于这个世界的认识发生了改变，我们开始相信一些原来不相信的事情，对我们之前深信不疑的事情也不再那么确信。(<strong>posterior</strong>).</p>
<blockquote>
<p>曾经相信过爱情，后来知道，原来爱情必须转化为亲情才可能持久，但是转化为亲情的爱情，犹如化入杯水中的冰块──它还是冰块吗？                    <br />
曾经相信过海枯石烂作为永恒不灭的表征，后来知道，原来海其实很容易枯，石，原来很容易烂。雨水，很可能不再来，沧海，不会再成桑田。原来，自己脚下所踩的地球，很容易被毁灭。海枯石烂的永恒，原来不存在。                   <br />
...                     <br />
相信与不相信之间，彷佛还有令人沉吟的深度。(龙应台《相信，不相信》）</p>
</blockquote>
<p>举上面例子的目的意在说明其实机器学习算法也许并非就是些模型，就是些数学而已，它也许能给我们提供看待世界的另一种角度，也许能带给我们一些有益的思考。关于闲话就说到这儿，以后我们有时间慢慢扯。</p>
<h2>Introduction to Decision Trees</h2>
<p>所谓决策树，顾名思义，是一种树，一种依托于策略抉择而建立起来的树。决策树中非叶节点均是决策节点，决策节点的取值确定了决策树具体下一步跳到那个节点，每个决策节点的分支分别代表了决策属性可能的取值；每一个叶节点代表了一个分类属性，即决策过程的完成。从根节点到叶节点的每一条路径代表了一个可能的决策过程。</p>
<p>举个例子，小王的目的是通过下周天气预报寻找什么时候人们会打高尔夫，他了解到人们决定是否打球的原因最主要取决于天气情况。而天气状况有晴，云和雨；气温用华氏温度表示；相对湿度用百分比；还有有无风。如此，我们便可以构造一棵决策树，如下（根据天气这个分类决策这天是否合适打网球):</p>
<p><img alt="golf" src="http://i1302.photobucket.com/albums/ag136/qingyuanxingsi/blog/golf_zps450da280.jpg" /></p>
<p>(如：沿着最左路径从上往下看会发现如果天气情况是晴、湿度小于70,则会打球。）</p>
<p>针对决策树，我们主要介绍两种比较典型的算法ID3以及C4.5,另外CART(Classification and Regression Tree)是另外使用的比较多的算法，商用的版本则有C5.0,它主要针对C4.5算法做了很多性能上的优化。具体针对CART以及C5.0的介绍本文将不再涉及。说明一点，我们总希望得到的树尽可能的简单(<strong>奥卡姆剃刀</strong>),这样我们由决策树抽取出的规则也能尽可能的简单，所以决策树算法的核心在于确定当前最好的分裂属性以保证树是尽可能简单的。 </p>
<h1>ID3</h1>
<hr />
<h2>ID3算法基本框架</h2>
<p>ID3算法是一个由Ross Quinlan发明的用于决策树的算法。它是一个启发式算法，具体算法框架可参见《机器学习》一书中的描述，如下所示:
                       <img alt="ID3" src="http://i1302.photobucket.com/albums/ag136/qingyuanxingsi/blog/id3_zpsaa2fe321.jpg" /></p>
<h2>分裂属性的选取</h2>
<p>判断测试某个属性为最佳的分类属性是ID3的核心问题，以下介绍两个比较重要的概念：信息熵和信息增益。</p>
<h3>信息熵</h3>
<p>为了精确地定义信息增益，我们先定义信息论中广泛使用的一个度量标准，称为熵(entropy),它刻画了任意样例集的纯度，另一种理解则是用来编码信息所需的最少比特位数。
\begin{equation}
Entropy(S) = -\sum_{i=1}^{c} p_i*log(p_i)
\end{equation}                                    <br />
其中，$p_i$是属性S属于类别i的概率。</p>
<h3>信息增益</h3>
<p>已经有了熵作为衡量训练样例集合纯度的标准，现在可以定义属性分类训练数据的效力的度量标准。这个标准被称为<strong>“信息增益（information gain）”</strong>。简单的说，一个属性的信息增益就是由于使用这个属性分割样例而导致的期望熵降低(或者说，样本按照某属性划分时造成熵减少的期望,个人结合前面理解，总结为用来衡量给定的属性区分训练样例的能力)。更精确地讲，一个属性A相对样例集合S的信息增益$Gain(S,A)$被定义为：
\begin{equation}
Gain(S,A)=Entropy(S) - \sum_{v \in S_v} \frac{|S_v|}{|S|}Entropy(S_v)
\end{equation}                 <br />
其中：
    $V(A)$是属性A的值域；
    $S$是样本集合；
    $S_v$是S在属性A上取值等于v的样本集合。</p>
<p>对于上述算法框架中迭代的每一步，针对样本集合S,我们分别算出针对每个可能的属性的信息增益值，并选择值最大的那个对应的属性作为我们该步的分裂属性即可。</p>
<h3>Python代码实现</h3>
<p>对于以上提到的ID3算法，基于Python我们给出了相应的源码实现，如下:(本博客中所有源码仅是算法思想的一个比较粗略的实现，很多方面还不成熟，特此说明，以后不再提及)</p>
<div class="highlight"><pre><span class="n">import</span> <span class="n">numpy</span> <span class="n">as</span> <span class="n">np</span>
<span class="n">import</span> <span class="n">math</span>
<span class="n">import</span> <span class="n">operator</span>

<span class="n">class</span> <span class="n">DTree_ID3</span><span class="o">:</span>
    <span class="n">def</span> <span class="n">runDT</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">features</span><span class="p">)</span><span class="o">:</span>
        <span class="n">classList</span> <span class="o">=</span> <span class="p">[</span><span class="n">sample</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">sample</span> <span class="n">in</span> <span class="n">dataset</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">classList</span><span class="p">.</span><span class="n">count</span><span class="p">(</span><span class="n">classList</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="n">len</span><span class="p">(</span><span class="n">classList</span><span class="p">)</span><span class="o">:</span>
            <span class="k">return</span> <span class="n">classList</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span><span class="o">:</span>
            <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">classify</span><span class="p">(</span><span class="n">classList</span><span class="p">)</span>

        <span class="n">max_index</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">Max_InfoGain</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="err">##</span><span class="n">index</span>
        <span class="n">max_fea</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="n">max_index</span><span class="p">]</span>
        <span class="n">myTree</span> <span class="o">=</span> <span class="p">{</span><span class="n">max_fea</span><span class="o">:</span><span class="p">{}}</span>
        <span class="n">fea_val</span> <span class="o">=</span> <span class="p">[</span><span class="n">sample</span><span class="p">[</span><span class="n">max_index</span><span class="p">]</span> <span class="k">for</span> <span class="n">sample</span> <span class="n">in</span> <span class="n">dataset</span><span class="p">]</span>
        <span class="n">unique</span> <span class="o">=</span> <span class="n">set</span><span class="p">(</span><span class="n">fea_val</span><span class="p">);</span>    
        <span class="n">del</span> <span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="n">max_index</span><span class="p">])</span> 
        <span class="k">for</span> <span class="n">values</span> <span class="n">in</span> <span class="n">unique</span><span class="o">:</span>          
            <span class="n">sub_dataset</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">splitDataSet</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">max_index</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span>         
            <span class="n">myTree</span><span class="p">[</span><span class="n">max_fea</span><span class="p">][</span><span class="n">values</span><span class="p">]</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">runDT</span><span class="p">(</span><span class="n">sub_dataset</span><span class="p">,</span><span class="n">features</span><span class="p">)</span> 
        <span class="n">features</span><span class="p">.</span><span class="n">insert</span><span class="p">(</span><span class="n">max_index</span><span class="p">,</span><span class="n">max_fea</span><span class="p">)</span>  
        <span class="k">return</span> <span class="n">myTree</span>

    <span class="n">def</span> <span class="n">classify</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="n">classList</span><span class="p">)</span><span class="o">:</span>
        <span class="n">classCount</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">vote</span> <span class="n">in</span> <span class="n">classList</span><span class="o">:</span>
            <span class="k">if</span> <span class="n">vote</span> <span class="n">not</span> <span class="n">in</span> <span class="n">classCount</span><span class="p">.</span><span class="n">keys</span><span class="p">()</span><span class="o">:</span>
                <span class="n">classCount</span><span class="p">[</span><span class="n">vote</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">classCount</span><span class="p">[</span><span class="n">vote</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">sortedClassCount</span> <span class="o">=</span> <span class="n">sorted</span><span class="p">(</span><span class="n">classCount</span><span class="p">.</span><span class="n">iteritems</span><span class="p">(),</span> <span class="n">key</span> <span class="o">=</span> <span class="n">operator</span><span class="p">.</span><span class="n">itemgetter</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">revese</span> <span class="o">=</span> <span class="n">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">sortedClassCount</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">def</span> <span class="n">Max_InfoGain</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">data_set</span><span class="p">)</span><span class="o">:</span>
        <span class="err">#</span><span class="n">compute</span> <span class="n">all</span> <span class="n">features</span> <span class="n">InfoGain</span><span class="p">,</span> <span class="k">return</span> <span class="n">the</span> <span class="n">maximal</span> <span class="n">one</span>
        <span class="n">Num_Fea</span> <span class="o">=</span> <span class="n">len</span><span class="p">(</span><span class="n">data_set</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="o">:</span><span class="p">])</span>
        <span class="err">#</span><span class="n">Num_Tup</span> <span class="o">=</span> <span class="n">len</span><span class="p">(</span><span class="n">data_set</span><span class="p">)</span>
        <span class="n">max_IG</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">max_Fea</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">for</span> <span class="n">i</span> <span class="n">in</span> <span class="n">range</span><span class="p">(</span><span class="n">Num_Fea</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">:</span>
            <span class="n">InfoGain</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">Info</span><span class="p">(</span><span class="n">data_set</span><span class="p">[</span><span class="o">:</span><span class="p">,[</span><span class="n">i</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">max_IG</span> <span class="o">&gt;</span> <span class="n">InfoGain</span><span class="p">)</span><span class="o">:</span>
                <span class="n">max_IG</span> <span class="o">=</span> <span class="n">InfoGain</span>
                <span class="n">max_Fea</span> <span class="o">=</span> <span class="n">i</span>
        <span class="k">return</span> <span class="n">max_Fea</span>

    <span class="n">def</span> <span class="n">Info</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span><span class="o">:</span>
        <span class="n">dic</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">tup</span> <span class="n">in</span> <span class="n">data</span><span class="o">:</span>
            <span class="k">if</span> <span class="n">tup</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="n">not</span> <span class="n">in</span> <span class="n">dic</span><span class="p">.</span><span class="n">keys</span><span class="p">()</span><span class="o">:</span>
                <span class="n">dic</span><span class="p">[</span><span class="n">tup</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="n">dic</span><span class="p">[</span><span class="n">tup</span><span class="p">[</span><span class="mi">0</span><span class="p">]][</span><span class="n">tup</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="n">elif</span> <span class="n">tup</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="n">not</span> <span class="n">in</span> <span class="n">dic</span><span class="p">[</span><span class="n">tup</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">:</span>
                <span class="n">dic</span><span class="p">[</span><span class="n">tup</span><span class="p">[</span><span class="mi">0</span><span class="p">]][</span><span class="n">tup</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="nl">else:</span>
                <span class="n">dic</span><span class="p">[</span><span class="n">tup</span><span class="p">[</span><span class="mi">0</span><span class="p">]][</span><span class="n">tup</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="n">S_total</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">key</span> <span class="n">in</span> <span class="n">dic</span><span class="o">:</span>
            <span class="n">s</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="k">for</span> <span class="n">label</span> <span class="n">in</span> <span class="n">dic</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">:</span>
                <span class="n">s</span> <span class="o">+=</span> <span class="n">dic</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">label</span><span class="p">]</span>
            <span class="n">S_each</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="k">for</span> <span class="n">label</span> <span class="n">in</span> <span class="n">dic</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">:</span>
                <span class="n">prob</span> <span class="o">=</span> <span class="kt">float</span><span class="p">(</span><span class="n">dic</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">label</span><span class="p">]</span><span class="o">/</span><span class="n">s</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">prob</span> <span class="o">!=</span><span class="mi">0</span> <span class="o">:</span>
                    <span class="n">S_each</span> <span class="o">-=</span> <span class="n">prob</span><span class="o">*</span><span class="n">math</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">prob</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">S_total</span> <span class="o">+=</span> <span class="n">s</span><span class="o">/</span><span class="n">len</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span><span class="o">*</span><span class="n">S_each</span>
        <span class="k">return</span> <span class="n">S_total</span>

    <span class="n">def</span> <span class="n">splitDataSet</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="n">dataSet</span><span class="p">,</span><span class="n">featureIndex</span><span class="p">,</span><span class="n">value</span><span class="p">)</span><span class="o">:</span>
        <span class="n">subDataSet</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">dataSet</span> <span class="o">=</span> <span class="n">dataSet</span><span class="p">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">sample</span> <span class="n">in</span> <span class="n">dataSet</span><span class="o">:</span>
            <span class="k">if</span> <span class="n">sample</span><span class="p">[</span><span class="n">featureIndex</span><span class="p">]</span> <span class="o">==</span> <span class="n">value</span><span class="o">:</span>
                <span class="n">reducedSample</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="o">:</span><span class="n">featureIndex</span><span class="p">]</span>  
                <span class="n">reducedSample</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="n">featureIndex</span><span class="o">+</span><span class="mi">1</span><span class="o">:</span><span class="p">])</span>  
                <span class="n">subDataSet</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">reducedSample</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">subDataSet</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">&quot;__main__&quot;</span><span class="o">:</span>
    <span class="n">dataSet</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="s">&quot;Cool&quot;</span><span class="p">,</span><span class="s">&quot;High&quot;</span><span class="p">,</span><span class="s">&quot;Yes&quot;</span><span class="p">,</span><span class="s">&quot;Yes&quot;</span><span class="p">],[</span><span class="s">&quot;Ugly&quot;</span><span class="p">,</span><span class="s">&quot;High&quot;</span><span class="p">,</span><span class="s">&quot;No&quot;</span><span class="p">,</span><span class="s">&quot;No&quot;</span><span class="p">],</span>
               <span class="p">[</span><span class="s">&quot;Cool&quot;</span><span class="p">,</span><span class="s">&quot;Low&quot;</span><span class="p">,</span><span class="s">&quot;No&quot;</span><span class="p">,</span><span class="s">&quot;No&quot;</span><span class="p">],[</span><span class="s">&quot;Cool&quot;</span><span class="p">,</span><span class="s">&quot;Low&quot;</span><span class="p">,</span><span class="s">&quot;Yes&quot;</span><span class="p">,</span><span class="s">&quot;Yes&quot;</span><span class="p">],</span>
               <span class="p">[</span><span class="s">&quot;Cool&quot;</span><span class="p">,</span><span class="s">&quot;Medium&quot;</span><span class="p">,</span><span class="s">&quot;No&quot;</span><span class="p">,</span><span class="s">&quot;Yes&quot;</span><span class="p">],[</span><span class="s">&quot;Ugly&quot;</span><span class="p">,</span><span class="s">&quot;Medium&quot;</span><span class="p">,</span><span class="s">&quot;Yes&quot;</span><span class="p">,</span><span class="s">&quot;No&quot;</span><span class="p">]])</span>
    <span class="n">featureSet</span> <span class="o">=</span> <span class="p">[</span><span class="s">&quot;Appearance&quot;</span><span class="p">,</span><span class="s">&quot;Salary&quot;</span><span class="p">,</span><span class="s">&quot;Office Guy&quot;</span><span class="p">]</span>
    <span class="n">dTree</span> <span class="o">=</span> <span class="n">DTree_ID3</span><span class="p">()</span>
    <span class="n">tree</span> <span class="o">=</span> <span class="n">dTree</span><span class="p">.</span><span class="n">runDT</span><span class="p">(</span><span class="n">dataSet</span><span class="p">,</span><span class="n">featureSet</span><span class="p">)</span>
    <span class="n">print</span><span class="p">(</span><span class="n">tree</span><span class="p">)</span>
</pre></div>


<h1>C4.5</h1>
<hr />
<p>C4.5决策树在ID3决策树的基础之上稍作改进，并克服了其两大缺点:</p>
<ol>
<li>用信息增益选择属性偏向于选择分枝比较多的属性，即取值多的属性;</li>
<li>不能处理连续属性.                </li>
</ol>
<h2>信息增益率</h2>
<p>C4.5选取了信息增益率作为选择决策属性的依据，克服了用信息增益来选择属性时偏向选择值多的属性的不足。信息增益率定义为： 
\begin{equation}
GainRatio(S,A)=\frac{Gain(S,A)}{SplitInfo(S,A)}
\end{equation}
其中$Gain(S,A)$和ID3算法中的信息增益计算相同，而$SplitInfo(S,A)$代表了按照属性A分裂样本集合S的广度和均匀性。
\begin{equation}
SplitInfo(S,A)=-\sum_{i=1}^{c} \frac{|S_i|}{|S|}log\frac{|S_i|}{|S|}
\end{equation}
其中$S_i$表示根据属性A分割S而成的样本子集;</p>
<h2>处理连续属性</h2>
<p>对于离散值，C4.5和ID3的处理方法相同，对于某个属性的值连续时，假设这这个节点上的数据集合样本为total，C4.5算法进行如下处理：   </p>
<ol>
<li>将样本数据该属性A上的具体数值按照升序排列，得到属性序列值：${A_1,A_2,A_3,...,A{total}}$</li>
<li>在上一步生成的序列值中生成total-1个分割点。第i个分割点的取值为$A_i$和$A_{i+1}$的均值，每个分割点都将属性序列划分为两个子集;</li>
<li>计算每个分割点的信息增益(Information Gain),得到total-1个信息增益。}</li>
<li>对分裂点的信息增益进行修正：减去log2(N-1)/|D|，其中N为可能的分裂点个数，D为数据集合大小。</li>
<li>选择修正后的信息增益值最大的分类点作为该属性的最佳分类点</li>
<li>计算最佳分裂点的信息增益率(Gain Ratio)作为该属性的Gain Ratio</li>
<li>选择Gain Ratio最大的属性作为分类属性。</li>
</ol>
<h1>总结</h1>
<p>决策树方法是机器学习算法中比较重要且较易于理解的一种分类算法，本文介绍了两种决策树算法，ID3和C4.5.决策树算法的核心在于分裂属性的选取上，对此，ID3采用了信息增益作为评估指标，但是ID3也有不能处理连续属性值和易于选取取值较多的属性，C4.5对这两个问题都给出了相应的解决方案。</p><script type= "text/javascript">
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
</script>

                </div><!-- /.entry-content -->
                <div class="comments">
                <h2>Comments !</h2>
                        <div id="disqus_thread"></div>
                        <script type="text/javascript">
                           var disqus_identifier = "Decision Tree.html";
                           (function() {
                                var dsq = document.createElement('script');
                                dsq.type = 'text/javascript'; dsq.async = true;
                                dsq.src = 'http://qingyuanxingsi.disqus.com/embed.js';
                                (document.getElementsByTagName('head')[0] ||
                                 document.getElementsByTagName('body')[0]).appendChild(dsq);
                          })();
                        </script>
                </div>
        </article>
</section>
        </div><!--/span-->

                <div class="span3 well sidebar-nav" id="sidebar">
<ul class="nav nav-list">
<li class="nav-header"><h4><i class="icon-external-link"></i>blogroll</h4></li>
    <li><a href="http://getpelican.com/"><i class="icon-external-link"></i>Pelican</a></li>
    <li><a href="http://python.org/"><i class="icon-external-link"></i>Python.org</a></li>
    <li><a href="http://www.google.com/"><i class="icon-external-link"></i>Google</a></li>
<li class="nav-header"><h4><i class="icon-home icon-large"></i> social</h4></li>
<li><a href="/" rel="alternate"><i class="icon-bookmark icon-large"></i>atom feed</a></li>
    <li><a href="http://www.renren.com"><i class="icon-renren-sign icon-large"></i>renren</a></li>

<li class="nav-header"><h4><i class="icon-folder-close icon-large"></i>Categories</h4></li>
<li>
<a href="/category/machine-learning.html">
    <i class="icon-folder-open icon-large"></i>Machine Learning
</a>
</li>

<li class="nav-header"><h4><i class="icon-tags icon-large"></i>Tags</h4></li>
<li class="tag-4">
    <a href="/tag/machine-learning.html">
        <i class="icon-tag icon-large"></i>Machine Learning
    </a>
</li>


</ul>        </div><!--/.well -->

      </div><!--/row-->

      <hr>

      <footer>
        <address id="about">
                Proudly powered by <a href="http://pelican.notmyidea.org/">Pelican <i class="icon-external-link"></i></a>,
                                which takes great advantage of <a href="http://python.org">Python <i class="icon-external-link"></i></a>.
        </address><!-- /#about -->

        <p>The theme is from <a href="http://twitter.github.com/bootstrap/">Bootstrap from Twitter <i class="icon-external-link"></i></a>,
                   and <a href="http://fortawesome.github.com/Font-Awesome/">Font-Awesome <i class="icon-external-link"></i></a>, thanks!</p>
      </footer>

    </div><!--/.fluid-container-->


<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
	var pageTracker = _gat._getTracker("UA-48582273-1");
pageTracker._trackPageview();
} catch(err) {}</script>
<script type="text/javascript">
    var disqus_shortname = 'qingyuanxingsi';
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>

    <!-- Le javascript -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="/theme/js/jquery-1.7.2.min.js"></script>
    <script src="/theme/js/bootstrap.min.js"></script>
  </body>
</html>