<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>Doodle World</title>
    <meta name="description" content="">
    <meta name="author" content="qingyuanxingsi">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
    <script src="/theme/html5.js"></script>
    <![endif]-->

    <!-- Le styles -->
    <link href="//netdna.bootstrapcdn.com/twitter-bootstrap/2.1.1/css/bootstrap.no-icons.min.css" rel="stylesheet">
    <link href="/theme/local.css" rel="stylesheet">
    <link href="/theme/pygments.css" rel="stylesheet">
    <link href="/theme/font-awesome.css" rel="stylesheet">
    <link href='http://fonts.googleapis.com/css?family=Gudea:400,400italic|Alegreya+SC' rel='stylesheet' type='text/css'>
</head>

<body>
<header class="blog-header">
  <div class="container">
    <div class="row-fluid">
      <div class="span9">
	<a href="" class="brand">Doodle World</a>
      </div>

      <div class="span3" id="blog-nav">
	<ul class="nav nav-pills pull-right">
            <li><a href="/pages/about.html">About</a></li>
	    <li >
	      <a href="/category/distributed-system.html ">Distributed System</a>
	    <li >
	      <a href="/category/life.html ">Life</a>
	    <li  class="active" >
	      <a href="/category/machine-learning.html ">Machine Learning</a>
	    <li >
	      <a href="/category/viewpoint.html ">Viewpoint</a>
	</ul>
      </div>
    </div> <!-- End of fluid row-->
  </div>   <!-- End of Container-->
</header>
    
<div class="container">
    <div class="content">
    <div class="row-fluid">

        <div class="span10">
    <div class='article'>
      <div class="row-fluid">
           <div class="content-title span9">
             <h1>机器学习系列(I):决策树算法</h1b>
           </div>
      </div>
    <div class="row-fluid">
      <div class="span2">
<p>一 03 三月 2014 </p>

<p style="text-align: left;">
Filed under <a href="/category/machine-learning.html">Machine Learning</a>
</p>
<p style="text-align: left;">
 
    Tags <a href="/tag/machine-learning.html">Machine Learning</a> </p>
<p>
</p>
      </div>
      
      <div class="span8">
	<h1>写在前面</h1>
<hr />
<p>好吧，今天我的博客在线下默默地开张了，花了好长时间才把中文显示的问题解决。言归正传，之所以开通这个博客，原因有二：</p>
<ul>
<li>对已经学过的知识进行梳理，保证学习过程的稳步前进；</li>
<li>敦促自己每周有一定的学习目标,以更好地推进自己的学习.</li>
</ul>
<p>关于这个博客其他的我就不说了，如果你觉得这个博客有点用，你愿意花点时间看看，我会灰常感激滴。如果你觉得这个博客没什么用，直接忽略就好。此外，这篇博客所有内容均host在Github上，本着分享，协作的精神，如果你愿意而且有时间欢迎投稿至qingyuanxingsi@163.com,I would be much glad to receive your mails.</p>
<h1>简介</h1>
<hr />
<h2>二三闲话</h2>
<p>这是本博客的第一篇博文，也是第一篇关于机器学习方面的博文，因此我想扯些闲话。就我而言，我觉得所有的机器学习算法并不只是模型本身那么简单，背后其实还有一些别的东西，从某种角度来说，它们也是模型的创立者认识世界的方式。</p>
<p>举贝叶斯为例，从他的模型中可能能推断出他也许认为万物皆有联系，所有的事物都不是孤立的，都是相互联系，相互影响的。一个事物的改变会引起其他事物的相应变化，世界是一个相互联系的整体。另，我经常听到人们抱怨这个世界不公平，这个世界并不是他们想要的那种模样；或者说自从多年前姚晨和凌潇肃离婚之后，好多人都不再相信爱情了(just a joke）。虽然说这是生活中再平常不过的桥段，从这两个例子中，也许我们能看到另外一些东西，我们很久很久以前都对这个世界有一些先入为主的认识(<strong>prior</strong>),我们愿意相信这个世界是公平的，爱情是非常美好的一件事。后来，慢慢的我们发现这个世界其实有很多不公平的事，我们发现这个世界里的爱情没我们想象的那么美好，我们看到了一些真实世界实实在在存在的事情(<strong>data</strong>),于是我们对于这个世界的认识发生了改变，我们开始相信一些原来不相信的事情，对我们之前深信不疑的事情也不再那么确信。(<strong>posterior</strong>)(关于这个模型我们下一次说吧).</p>
<blockquote>
<p>曾经相信过爱情，后来知道，原来爱情必须转化为亲情才可能持久，但是转化为亲情的爱情，犹如化入杯水中的冰块──它还是冰块吗？                    <br />
曾经相信过海枯石烂作为永恒不灭的表征，后来知道，原来海其实很容易枯，石，原来很容易烂。雨水，很可能不再来，沧海，不会再成桑田。原来，自己脚下所踩的地球，很容易被毁灭。海枯石烂的永恒，原来不存在。                   <br />
...                     <br />
相信与不相信之间，彷佛还有令人沉吟的深度。(龙应台《相信，不相信》）</p>
</blockquote>
<p>举上面例子的目的意在说明其实机器学习算法也许并非就是些模型，就是些数学而已，它也许能给我们提供看待世界的另一种角度，也许能带给我们一些有益的思考。关于闲话就说到这儿，以后我们有时间慢慢扯。</p>
<h2>Introduction to Decision Trees</h2>
<p>所谓决策树，顾名思义，是一种树，一种依托于策略抉择而建立起来的树。决策树中非叶节点(非根节点)均是决策节点，决策节点的取值决定了决策树具体下一步跳到那个节点，每个决策节点的分支则分别代表了决策属性可能的取值；每一个叶节点代表了一个分类属性，即决策过程的完成。从根节点到叶节点的每一条路径代表了一个可能的决策过程。</p>
<p>举个例子，也许大家能对决策树到底是什么有一个更为清楚直观的认识:</p>
<p>一个非常经典的例子是一个女生找对象的过程，在女孩决定是否相亲的过程中可能产生如下对话:</p>
<div class="highlight"><pre><span class="err">女儿：多大年纪了？</span>
<span class="err">母亲：</span><span class="mi">26</span><span class="err">。</span>
<span class="err">女儿：长的帅不帅？</span>
<span class="err">母亲：挺帅的。</span>
<span class="err">女儿：收入高不？</span>
<span class="err">母亲：不算很高，中等情况。</span>
<span class="err">女儿：是公务员不？</span>
<span class="err">母亲：是，在税务局上班呢。</span>
<span class="err">女儿：那好，我去见见。</span>
</pre></div>


<p>这个女孩的决策过程就是典型的分类树决策。相当于通过年龄、长相、收入和是否公务员对将男人分为两个类别：见和不见。假设这个女孩对男人的要求是：30岁以下、长相中等以上并且是高收入者或中等以上收入的公务员，那么这个可以用下图表示女孩的决策逻辑：</p>
<p><img alt="girl" src="http://i1302.photobucket.com/albums/ag136/qingyuanxingsi/APPLE/Markdown/girl_zpsd5a3cfed.jpg" /></p>
<p>根据奥卡姆剃刀原则(<code>Simpler is better</code>),我们尽可能想构造得到的决策书尽可能的小。因此，如何选择上图中决策属性是所有决策树算法的核心所在。我们尽量在每一步要有限选取最有分辨能力的属性作为决策属性，以保证树尽可能的小。针对决策树，我们主要介绍两种比较典型的算法ID3以及C4.5,另外CART(Classification and Regression Tree)是另外使用的比较多的算法，商用的版本则有C5.0,它主要针对C4.5算法做了很多性能上的优化。具体针对CART以及C5.0的介绍本文将不再涉及。</p>
<h1>ID3</h1>
<hr />
<h2>ID3算法基本框架</h2>
<p>ID3算法是一个由Ross Quinlan发明的用于决策树的算法。它是一个启发式算法，具体算法框架可参见《机器学习》一书中的描述，如下所示:
                       <img alt="ID3" src="http://i1302.photobucket.com/albums/ag136/qingyuanxingsi/blog/id3_zpsaa2fe321.jpg" /></p>
<h2>分裂属性的选取</h2>
<p>如上图算法框架所示，判断测试某个属性为最佳的分类属性是ID3的核心问题，以下介绍两个比较重要的概念：信息熵和信息增益。</p>
<h3>信息熵</h3>
<p>为了精确地定义信息增益，我们先定义信息论中广泛使用的一个度量标准，称为熵(entropy),它刻画了任意样例集的纯度，另一种理解则是用来编码信息所需的最少比特位数。
\begin{equation}
Entropy(S) = -\sum_{i=1}^{c} p_ilog(p_i)
\end{equation}                                    <br />
其中，$p_i$是属性S属于类别i的概率。</p>
<h3>信息增益</h3>
<p>已经有了熵作为衡量训练样例集合纯度的标准，现在可以定义属性分类训练数据的效力的度量标准。这个标准被称为<strong>“信息增益（information gain）”</strong>。简单的说，一个属性的信息增益就是由于使用这个属性分割样例而导致的期望熵降低(或者说，样本按照某属性划分时造成熵减少的期望,个人结合前面理解，总结为用来衡量给定的属性区分训练样例的能力)。更精确地讲，一个属性A相对样例集合S的信息增益$Gain(S,A)$被定义为：
\begin{equation}
Gain(S,A)=Entropy(S) - \sum_{v \in S_v} \frac{|S_v|}{|S|}Entropy(S_v)
\end{equation}                 <br />
其中：
    $V(A)$是属性A的值域；
    $S$是样本集合；
    $S_v$是S在属性A上取值等于v的样本集合。</p>
<p>对于上述算法框架中迭代的每一步，针对样本集合S,我们分别算出针对每个可能的属性的信息增益值，并选择值最大的那个对应的属性作为我们该步的分裂属性即可。依次迭代，便能构造我们想要的决策树。</p>
<h3>Python代码实现</h3>
<p>实践出真知，磨刀霍霍，我们小小地实现一下。对于以上提到的ID3算法，基于Python我们给出了相应的源码实现，如下:(本博客中所有源码仅是算法思想的一个比较粗略的实现，很多方面还不成熟，特此说明，以后不再提及)</p>
<div class="highlight"><pre><span class="n">import</span> <span class="n">numpy</span> <span class="n">as</span> <span class="n">np</span>
<span class="n">import</span> <span class="n">math</span>
<span class="n">import</span> <span class="n">operator</span>

<span class="n">class</span> <span class="n">DTree_ID3</span><span class="o">:</span>
    <span class="n">def</span> <span class="n">runDT</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">features</span><span class="p">)</span><span class="o">:</span>
        <span class="n">classList</span> <span class="o">=</span> <span class="p">[</span><span class="n">sample</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">sample</span> <span class="n">in</span> <span class="n">dataset</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">classList</span><span class="p">.</span><span class="n">count</span><span class="p">(</span><span class="n">classList</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="n">len</span><span class="p">(</span><span class="n">classList</span><span class="p">)</span><span class="o">:</span>
            <span class="k">return</span> <span class="n">classList</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span><span class="o">:</span>
            <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">classify</span><span class="p">(</span><span class="n">classList</span><span class="p">)</span>

        <span class="n">max_index</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">Max_InfoGain</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="err">##</span><span class="n">index</span>
        <span class="n">max_fea</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="n">max_index</span><span class="p">]</span>
        <span class="n">myTree</span> <span class="o">=</span> <span class="p">{</span><span class="n">max_fea</span><span class="o">:</span><span class="p">{}}</span>
        <span class="n">fea_val</span> <span class="o">=</span> <span class="p">[</span><span class="n">sample</span><span class="p">[</span><span class="n">max_index</span><span class="p">]</span> <span class="k">for</span> <span class="n">sample</span> <span class="n">in</span> <span class="n">dataset</span><span class="p">]</span>
        <span class="n">unique</span> <span class="o">=</span> <span class="n">set</span><span class="p">(</span><span class="n">fea_val</span><span class="p">);</span>    
        <span class="n">del</span> <span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="n">max_index</span><span class="p">])</span> 
        <span class="k">for</span> <span class="n">values</span> <span class="n">in</span> <span class="n">unique</span><span class="o">:</span>          
            <span class="n">sub_dataset</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">splitDataSet</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">max_index</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span>         
            <span class="n">myTree</span><span class="p">[</span><span class="n">max_fea</span><span class="p">][</span><span class="n">values</span><span class="p">]</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">runDT</span><span class="p">(</span><span class="n">sub_dataset</span><span class="p">,</span><span class="n">features</span><span class="p">)</span> 
        <span class="n">features</span><span class="p">.</span><span class="n">insert</span><span class="p">(</span><span class="n">max_index</span><span class="p">,</span><span class="n">max_fea</span><span class="p">)</span>  
        <span class="k">return</span> <span class="n">myTree</span>

    <span class="n">def</span> <span class="n">classify</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="n">classList</span><span class="p">)</span><span class="o">:</span>
        <span class="n">classCount</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">vote</span> <span class="n">in</span> <span class="n">classList</span><span class="o">:</span>
            <span class="k">if</span> <span class="n">vote</span> <span class="n">not</span> <span class="n">in</span> <span class="n">classCount</span><span class="p">.</span><span class="n">keys</span><span class="p">()</span><span class="o">:</span>
                <span class="n">classCount</span><span class="p">[</span><span class="n">vote</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">classCount</span><span class="p">[</span><span class="n">vote</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">sortedClassCount</span> <span class="o">=</span> <span class="n">sorted</span><span class="p">(</span><span class="n">classCount</span><span class="p">.</span><span class="n">iteritems</span><span class="p">(),</span> <span class="n">key</span> <span class="o">=</span> <span class="n">operator</span><span class="p">.</span><span class="n">itemgetter</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">revese</span> <span class="o">=</span> <span class="n">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">sortedClassCount</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">def</span> <span class="n">Max_InfoGain</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">data_set</span><span class="p">)</span><span class="o">:</span>
        <span class="err">#</span><span class="n">compute</span> <span class="n">all</span> <span class="n">features</span> <span class="n">InfoGain</span><span class="p">,</span> <span class="k">return</span> <span class="n">the</span> <span class="n">maximal</span> <span class="n">one</span>
        <span class="n">Num_Fea</span> <span class="o">=</span> <span class="n">len</span><span class="p">(</span><span class="n">data_set</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="o">:</span><span class="p">])</span>
        <span class="err">#</span><span class="n">Num_Tup</span> <span class="o">=</span> <span class="n">len</span><span class="p">(</span><span class="n">data_set</span><span class="p">)</span>
        <span class="n">max_IG</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">max_Fea</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">for</span> <span class="n">i</span> <span class="n">in</span> <span class="n">range</span><span class="p">(</span><span class="n">Num_Fea</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">:</span>
            <span class="n">InfoGain</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">Info</span><span class="p">(</span><span class="n">data_set</span><span class="p">[</span><span class="o">:</span><span class="p">,[</span><span class="n">i</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">max_IG</span> <span class="o">&gt;</span> <span class="n">InfoGain</span><span class="p">)</span><span class="o">:</span>
                <span class="n">max_IG</span> <span class="o">=</span> <span class="n">InfoGain</span>
                <span class="n">max_Fea</span> <span class="o">=</span> <span class="n">i</span>
        <span class="k">return</span> <span class="n">max_Fea</span>

    <span class="n">def</span> <span class="n">Info</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span><span class="o">:</span>
        <span class="n">dic</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">tup</span> <span class="n">in</span> <span class="n">data</span><span class="o">:</span>
            <span class="k">if</span> <span class="n">tup</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="n">not</span> <span class="n">in</span> <span class="n">dic</span><span class="p">.</span><span class="n">keys</span><span class="p">()</span><span class="o">:</span>
                <span class="n">dic</span><span class="p">[</span><span class="n">tup</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="n">dic</span><span class="p">[</span><span class="n">tup</span><span class="p">[</span><span class="mi">0</span><span class="p">]][</span><span class="n">tup</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="n">elif</span> <span class="n">tup</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="n">not</span> <span class="n">in</span> <span class="n">dic</span><span class="p">[</span><span class="n">tup</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">:</span>
                <span class="n">dic</span><span class="p">[</span><span class="n">tup</span><span class="p">[</span><span class="mi">0</span><span class="p">]][</span><span class="n">tup</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="nl">else:</span>
                <span class="n">dic</span><span class="p">[</span><span class="n">tup</span><span class="p">[</span><span class="mi">0</span><span class="p">]][</span><span class="n">tup</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="n">S_total</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">key</span> <span class="n">in</span> <span class="n">dic</span><span class="o">:</span>
            <span class="n">s</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="k">for</span> <span class="n">label</span> <span class="n">in</span> <span class="n">dic</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">:</span>
                <span class="n">s</span> <span class="o">+=</span> <span class="n">dic</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">label</span><span class="p">]</span>
            <span class="n">S_each</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="k">for</span> <span class="n">label</span> <span class="n">in</span> <span class="n">dic</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">:</span>
                <span class="n">prob</span> <span class="o">=</span> <span class="kt">float</span><span class="p">(</span><span class="n">dic</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">label</span><span class="p">]</span><span class="o">/</span><span class="n">s</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">prob</span> <span class="o">!=</span><span class="mi">0</span> <span class="o">:</span>
                    <span class="n">S_each</span> <span class="o">-=</span> <span class="n">prob</span><span class="o">*</span><span class="n">math</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">prob</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">S_total</span> <span class="o">+=</span> <span class="n">s</span><span class="o">/</span><span class="n">len</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span><span class="o">*</span><span class="n">S_each</span>
        <span class="k">return</span> <span class="n">S_total</span>

    <span class="n">def</span> <span class="n">splitDataSet</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="n">dataSet</span><span class="p">,</span><span class="n">featureIndex</span><span class="p">,</span><span class="n">value</span><span class="p">)</span><span class="o">:</span>
        <span class="n">subDataSet</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">dataSet</span> <span class="o">=</span> <span class="n">dataSet</span><span class="p">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">sample</span> <span class="n">in</span> <span class="n">dataSet</span><span class="o">:</span>
            <span class="k">if</span> <span class="n">sample</span><span class="p">[</span><span class="n">featureIndex</span><span class="p">]</span> <span class="o">==</span> <span class="n">value</span><span class="o">:</span>
                <span class="n">reducedSample</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="o">:</span><span class="n">featureIndex</span><span class="p">]</span>  
                <span class="n">reducedSample</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="n">featureIndex</span><span class="o">+</span><span class="mi">1</span><span class="o">:</span><span class="p">])</span>  
                <span class="n">subDataSet</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">reducedSample</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">subDataSet</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">&quot;__main__&quot;</span><span class="o">:</span>
    <span class="n">dataSet</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="s">&quot;Cool&quot;</span><span class="p">,</span><span class="s">&quot;High&quot;</span><span class="p">,</span><span class="s">&quot;Yes&quot;</span><span class="p">,</span><span class="s">&quot;Yes&quot;</span><span class="p">],[</span><span class="s">&quot;Ugly&quot;</span><span class="p">,</span><span class="s">&quot;High&quot;</span><span class="p">,</span><span class="s">&quot;No&quot;</span><span class="p">,</span><span class="s">&quot;No&quot;</span><span class="p">],</span>
               <span class="p">[</span><span class="s">&quot;Cool&quot;</span><span class="p">,</span><span class="s">&quot;Low&quot;</span><span class="p">,</span><span class="s">&quot;No&quot;</span><span class="p">,</span><span class="s">&quot;No&quot;</span><span class="p">],[</span><span class="s">&quot;Cool&quot;</span><span class="p">,</span><span class="s">&quot;Low&quot;</span><span class="p">,</span><span class="s">&quot;Yes&quot;</span><span class="p">,</span><span class="s">&quot;Yes&quot;</span><span class="p">],</span>
               <span class="p">[</span><span class="s">&quot;Cool&quot;</span><span class="p">,</span><span class="s">&quot;Medium&quot;</span><span class="p">,</span><span class="s">&quot;No&quot;</span><span class="p">,</span><span class="s">&quot;Yes&quot;</span><span class="p">],[</span><span class="s">&quot;Ugly&quot;</span><span class="p">,</span><span class="s">&quot;Medium&quot;</span><span class="p">,</span><span class="s">&quot;Yes&quot;</span><span class="p">,</span><span class="s">&quot;No&quot;</span><span class="p">]])</span>
    <span class="n">featureSet</span> <span class="o">=</span> <span class="p">[</span><span class="s">&quot;Appearance&quot;</span><span class="p">,</span><span class="s">&quot;Salary&quot;</span><span class="p">,</span><span class="s">&quot;Office Guy&quot;</span><span class="p">]</span>
    <span class="n">dTree</span> <span class="o">=</span> <span class="n">DTree_ID3</span><span class="p">()</span>
    <span class="n">tree</span> <span class="o">=</span> <span class="n">dTree</span><span class="p">.</span><span class="n">runDT</span><span class="p">(</span><span class="n">dataSet</span><span class="p">,</span><span class="n">featureSet</span><span class="p">)</span>
    <span class="n">print</span><span class="p">(</span><span class="n">tree</span><span class="p">)</span>
</pre></div>


<h1>C4.5</h1>
<hr />
<p>C4.5决策树在ID3决策树的基础之上稍作改进，并克服了其两大缺点:</p>
<ol>
<li>用信息增益选择属性偏向于选择分枝比较多的属性，即取值多的属性;</li>
<li>不能处理连续属性.                </li>
</ol>
<p>对于这两个问题，C4.5都给出了具体的解决方案，以下做一个简要的阐述。</p>
<h2>信息增益率</h2>
<p>C4.5选取了信息增益率作为选择决策属性的依据，克服了用信息增益来选择属性时偏向选择值多的属性的不足。信息增益率定义为： 
\begin{equation}
GainRatio(S,A)=\frac{Gain(S,A)}{SplitInfo(S,A)}
\end{equation}
其中$Gain(S,A)$和ID3算法中的信息增益计算相同，而$SplitInfo(S,A)$代表了按照属性A分裂样本集合S的广度和均匀性。
\begin{equation}
SplitInfo(S,A)=-\sum_{i=1}^{c} \frac{|S_i|}{|S|}log\frac{|S_i|}{|S|}
\end{equation}
其中$S_i$表示根据属性A分割S而成的样本子集;</p>
<h2>处理连续属性</h2>
<p>对于离散值，C4.5和ID3的处理方法相同，对于某个属性的值连续时，假设这这个节点上的数据集合样本为total，C4.5算法进行如下处理：   </p>
<ol>
<li>将样本数据该属性A上的具体数值按照升序排列，得到属性序列值：${A_1,A_2,A_3,...,A{total}}$</li>
<li>在上一步生成的序列值中生成total-1个分割点。第i个分割点的取值为$A_i$和$A_{i+1}$的均值，每个分割点都将属性序列划分为两个子集;</li>
<li>计算每个分割点的信息增益(Information Gain),得到total-1个信息增益。}</li>
<li>对分裂点的信息增益进行修正：减去log2(N-1)/|D|，其中N为可能的分裂点个数，D为数据集合大小。</li>
<li>选择修正后的信息增益值最大的分类点作为该属性的最佳分类点</li>
<li>计算最佳分裂点的信息增益率(Gain Ratio)作为该属性的Gain Ratio</li>
<li>选择Gain Ratio最大的属性作为分类属性。</li>
</ol>
<h1>总结</h1>
<p>决策树方法是机器学习算法中比较重要且较易于理解的一种分类算法，本文介绍了两种决策树算法，ID3和C4.5.决策树算法的核心在于分裂属性的选取上，对此，ID3采用了信息增益作为评估指标，但是ID3也有不能处理连续属性值和易于选取取值较多的属性，C4.5对这两个问题都给出了相应的解决方案。</p><script type= "text/javascript">
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
</script>

	<hr />
      </div>
    </div>
    <div class="span10">
      <h3>Comments</h3>
    
<div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'qingyuanxingsi'; 

    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>  
    </div>
        </div>
        
        
    </div>     </div> </div>

<!--footer-->
<div class="container">
  <div class="well" style="background-color: #E9EFF6">
    <div id="blog-footer">
      <div class="row-fluid">
	<div class="social span2" align="center" id="socialist">
	  <ul class="nav nav-list">
	    <li class="nav-header">
	      Social
	    </li>
	    <li><a href="https://github.com/qingyuanxingsi"><i class="icon-Github" style="color: #1f334b"></i>Github</a></li>

	  </ul>
	</div>
        <div class="links span2" align="center">
          <ul class="nav nav-list">
            <li class="nav-header"> 
              Links
            </li>
            
            <li><a href="http://freemind.pluskid.org">Pluskid</a></li>
            <li><a href="https://github.com/julycoding/The-Art-Of-Programming-By-July">结构之法 算法之道</a></li>
            <li><a href="http://www.google.com/">Google</a></li>
          </ul>
        </div>
	<div class="site-nav span2" align="center">
          <ul class="nav nav-list" id="site-links">
            <li class="nav-header"> 
              Site
            </li>
            <li><a href=""><i class="icon-home" style="color: #1f334b">
                </i>Home</a></li>
            <li><a href="/archives.html"><i class="icon-list" style="color: #1f334b">
                </i>Archives</a></li>
	    <li><a href="/tags.html"><i class="icon-tags" style="color: #1f334b">
                </i>Tags</a></li>
	    
            <li><a href="/" rel="alternate">
                <i class="icon-rss-sign" style="color: #1f334b"></i>
                Atom Feed</a></li>
	  </ul>

        </div>

      </div> <!--end of fluid row-->
    </div> <!--end of blog-footer-->
    <hr />
    <p align="center"><a href="">Doodle World</a>
      &copy; qingyuanxingsi
    Powered by <a href="github.com/getpelican/pelican">Pelican</a> and
        <a href="https://twitter.github.com/bootstrap">Twitter Bootstrap</a>. 
        Icons by <a href="http://fortawesome.github.com/Font-Awesome">Font Awesome</a> and 
        <a href="http://gregoryloucas.github.com/Font-Awesome-More">Font Awesome More</a></p>

  </div> <!--end of well -->
</div> <!--end of container -->

<!--/footer-->
<script src="//ajax.googleapis.com/ajax/libs/jquery/1.8.3/jquery.min.js"></script>
<script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.2.2/js/bootstrap.min.js"></script>


<script>var _gaq=[['_setAccount','UA-48582273-1'],['_trackPageview']];(function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];g.src='//www.google-analytics.com/ga.js';s.parentNode.insertBefore(g,s)}(document,'script'))</script>

</body>
</html>